**Unintended bias evaluation: An analysis of hate speech detection and gender bias mitigation on social media using ensemble learning**
========================================================================================================================


        | article{nascimento2022bias,
        | title = {Unintended bias evaluation: An analysis of hate speech detection and gender bias mitigation on social media using ensemble learning},
        | author = {Francimaria R.S. Nascimento and George D.C. Cavalcanti and MÃ¡rjory {Da Costa-Abreu}},
        | journal = {Expert Systems with Applications},
        | pages = {117032},
        | year = {2022},
        | issn = {0957-4174},
        | doi = {https://doi.org/10.1016/j.eswa.2022.117032},
        | url = {https://www.sciencedirect.com/science/article/pii/S095741742200447X},
        | keywords = {Hate speech detection, Ensemble learning, Gender bias, Multi-features}}


**Syntetic test set**:
========================================================================================================================

The idea is to build sentences changing only the identity term, for instance, "**Women** should be protected" and "**Men** should be protected".
We define several templates filled with the terms described in bias_data. Thus, each identity term occurs in the same context. 

The synthetic test set created comprises 1,248 samples, of which 648 are non-hateful, and 600 are hateful, and all identity terms appear in the same contexts. 



